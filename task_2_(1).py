# -*- coding: utf-8 -*-
"""Task_2 (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/Sourav61/Sparks-Foundation/blob/main/Sparks-Foundation-Task-2.ipynb
"""

from google.colab import drive
drive.mount('/content/drive')

"""<h1><b>Author: Sourav Pahwa</b></h1>
<h2>GRIPMAY2021 - The Sparks Foundation - Data Science & Business Analytics Internship</h2>
<h3><b>Task-2 : Prediction using Unsupervised Machine Learning</b></h3>
<ul style="list-style-type:square"><h4><li>From the given ‘Iris’ dataset, predict the optimum number of clusters 
and represent it visually.</li></h4></ul>
"""

#importing the required libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import missingno as msno

#importing the given data
Data = pd.read_csv("Iris.csv")

print("Data imported successfully")
#Checking the Shape of the data
print(Data.shape)
#getting info about data
Data.info()

#Here we are visualising the null values.

msno.matrix(Data.sample(150))

msno.bar(Data.sample(150))

#Species is dropped from our dataset
Data.drop(['Species'],axis=1,inplace=True)
#Id is also dropped from our dataset
Data.drop(['Id'],axis=1,inplace=True)

#We are looking at the first 10 values of our dataset
print(Data.head(10))
#We are looking at the last 10 values of our dataset
Data.tail(10)

#Inspecting the dataframe
# This function displays the datatype,levels 0f variables and number of levels in each column of the given Iris dataframe.Here lambda is used to pass arguments

def inspect(data):
    return pd.DataFrame({"Data Type":data.dtypes,"No of Levels":data.apply(lambda x: x.nunique(),axis=0), "Levels":data.apply(lambda x: str(x.unique()),axis=0)})
inspect(Data)

#Here we are analysing our dataset mathematically. 

Data.describe(include='all')

#Here we are looking at the correlation between various entities in our dataset

fig = plt.figure(figsize = (12,10))
sns.heatmap(Data.corr(), cmap='Blues', annot = True)

# Creating a pairplot with hue defined by Clicked on Ad column
sns.pairplot(Data, vars = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm'], palette = 'husl')

#checking the distribution of highly correlated numerical features with different variables
cols = ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']
plt.figure(figsize=(20,4), dpi=100)
i = 1
for col in cols:
    plt.subplot(1,11,i)
    sns.distplot(Data[col])
    i = i+1
plt.tight_layout()
plt.show()

# Finding the optimum number of clusters for k-means classification

x = Data.iloc[:, [0, 1, 2, 3]].values

from sklearn.cluster import KMeans
a = []

for i in range(1, 11):
    kmeans = KMeans(n_clusters = i, init = 'k-means++', 
                    max_iter = 300, n_init = 10, random_state = 0)
    kmeans.fit(x)
    a.append(kmeans.inertia_)

"""<b>We plot reduction in variance,for per value of k on that basis we plot one graph in which on y axis there is reduction in variance and on x axis there is no. of clusters.This method is known as elbow method.</b>"""

# Plotting the results onto a line graph, 
# `allowing us to observe 'The elbow'
plt.plot(range(1, 11), a)
plt.title('The elbow method')
plt.xlabel('Number of clusters')
plt.ylabel('Within Cluster Sum of the Squares')
plt.show()

# Applying kmeans to the dataset / Creating the kmeans classifier
kmeans = KMeans(n_clusters = 3, init = 'k-means++',
                max_iter = 300, n_init = 10, random_state = 0)
y_kmeans = kmeans.fit_predict(x)

# Visualising the clusters - On the first two columns
plt.scatter(x[y_kmeans == 0, 0], x[y_kmeans == 0, 1], 
            s = 100, c = 'orange', label = 'Iris-setosa')
plt.scatter(x[y_kmeans == 1, 0], x[y_kmeans == 1, 1], 
            s = 100, c = 'purple', label = 'Iris-versicolour')
plt.scatter(x[y_kmeans == 2, 0], x[y_kmeans == 2, 1],
            s = 100, c = 'green', label = 'Iris-virginica')

# Plotting the centroids of the clusters
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:,1], 
            s = 100, c = 'yellow', label = 'Centroids')

#plt.show()
plt.legend()